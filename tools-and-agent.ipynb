{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9062fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_ingestion.github_data_reader as reader\n",
    "import data_ingestion.chordpro_parser as parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c549c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = reader.read_github_data('Asacri', 'asacriband-chords')\n",
    "chunks = parser.parse_and_chunk(songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55a407ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52b4f0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "qd_client = QdrantClient('http://localhost:6333')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b521e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensionality = 384\n",
    "model_name = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'\n",
    "collection_name = \"asacriband-chords\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81ae192b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if qd_client.collection_exists(collection_name):\n",
    "    qd_client.delete_collection(collection_name)\n",
    "\n",
    "qd_client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=dimensionality,\n",
    "        distance=models.Distance.COSINE\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "368c0f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/qdrant_client/embed/embedder.py:75: UserWarning: The model sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 now uses mean pooling instead of CLS embedding. In order to preserve the previous behaviour, consider either pinning fastembed version to 0.5.1 or using `add_custom_model` functionality.\n",
      "  model = TextEmbedding(model_name=model_name, **options)\n",
      "Exception ignored in: <function tqdm.__del__ at 0x146814040>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "    self.close()\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/tqdm/notebook.py\", line 279, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "AttributeError: 'tqdm' object has no attribute 'disp'\n",
      "Exception ignored in: <function tqdm.__del__ at 0x146814040>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "    self.close()\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/tqdm/notebook.py\", line 279, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "AttributeError: 'tqdm' object has no attribute 'disp'\n",
      "Exception ignored in: <function tqdm.__del__ at 0x146814040>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "    self.close()\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/tqdm/notebook.py\", line 279, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "AttributeError: 'tqdm' object has no attribute 'disp'\n",
      "Exception ignored in: <function tqdm.__del__ at 0x146814040>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "    self.close()\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/tqdm/notebook.py\", line 279, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "AttributeError: 'tqdm' object has no attribute 'disp'\n",
      "Exception ignored in: <function tqdm.__del__ at 0x146814040>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "    self.close()\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/tqdm/notebook.py\", line 282, in close\n",
      "    self.disp(bar_style='success', check_delay=False)\n",
      "AttributeError: 'tqdm' object has no attribute 'disp'\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='vector_search' coro=<_call_tool() done, defined at /Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/pydantic_ai/_agent_graph.py:1026> exception=RuntimeError('dictionary changed size during iteration')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/pydantic_ai/_agent_graph.py\", line 1033, in _call_tool\n",
      "    tool_result = await tool_manager.handle_call(tool_call)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/pydantic_ai/_tool_manager.py\", line 112, in handle_call\n",
      "    return await self._call_function_tool(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<7 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/pydantic_ai/_tool_manager.py\", line 237, in _call_function_tool\n",
      "    tool_result = await self._call_tool(call, allow_partial, wrap_validation_errors)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/pydantic_ai/_tool_manager.py\", line 160, in _call_tool\n",
      "    result = await self.toolset.call_tool(name, args_dict, ctx, tool)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/pydantic_ai/toolsets/combined.py\", line 90, in call_tool\n",
      "    return await tool.source_toolset.call_tool(name, tool_args, ctx, tool.source_tool)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/pydantic_ai/toolsets/combined.py\", line 90, in call_tool\n",
      "    return await tool.source_toolset.call_tool(name, tool_args, ctx, tool.source_tool)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/pydantic_ai/toolsets/function.py\", line 350, in call_tool\n",
      "    return await tool.call_func(tool_args, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/pydantic_ai/_function_schema.py\", line 55, in call\n",
      "    return await run_in_executor(function, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/pydantic_ai/_utils.py\", line 47, in run_in_executor\n",
      "    return await run_sync(wrapped_func)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 2485, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 976, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/var/folders/km/dql4gckx6ps4lrl0mdrhnsbh0000gn/T/ipykernel_76718/2606569480.py\", line 25, in vector_search\n",
      "    query_points = qd_client.query_points(\n",
      "        collection_name=collection_name,\n",
      "    ...<2 lines>...\n",
      "        with_payload=True\n",
      "    )\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/qdrant_client/qdrant_client.py\", line 562, in query_points\n",
      "    next(\n",
      "    ~~~~^\n",
      "        iter(\n",
      "        ^^^^^\n",
      "    ...<3 lines>...\n",
      "        )\n",
      "        ^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/qdrant_client/qdrant_fastembed.py\", line 875, in _embed_models\n",
      "    yield from self._model_embedder.embed_models(\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/qdrant_client/embed/model_embedder.py\", line 71, in embed_models\n",
      "    yield from self.embed_models_batch(\n",
      "        raw_models_batch, is_query, inference_batch_size=batch_size\n",
      "    )\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/qdrant_client/embed/model_embedder.py\", line 147, in embed_models_batch\n",
      "    yield from (\n",
      "    ...<7 lines>...\n",
      "    )\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/qdrant_client/embed/model_embedder.py\", line 148, in <genexpr>\n",
      "    self._process_model(\n",
      "    ~~~~~~~~~~~~~~~~~~~^\n",
      "        raw_model,\n",
      "        ^^^^^^^^^^\n",
      "    ...<2 lines>...\n",
      "        inference_batch_size=inference_batch_size,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/qdrant_client/embed/model_embedder.py\", line 233, in _process_model\n",
      "    self._drain_accumulator(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        data, is_query=is_query, inference_batch_size=inference_batch_size\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/qdrant_client/embed/model_embedder.py\", line 315, in _drain_accumulator\n",
      "    self._embed_accumulator(is_query=is_query, inference_batch_size=inference_batch_size)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/qdrant_client/embed/model_embedder.py\", line 391, in _embed_accumulator\n",
      "    for model, data in self._batch_accumulator.items():\n",
      "                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "RuntimeError: dictionary changed size during iteration\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='vector_search' coro=<_call_tool() done, defined at /Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/pydantic_ai/_agent_graph.py:1026> exception=RuntimeError('dictionary changed size during iteration')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/pydantic_ai/_agent_graph.py\", line 1033, in _call_tool\n",
      "    tool_result = await tool_manager.handle_call(tool_call)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/pydantic_ai/_tool_manager.py\", line 112, in handle_call\n",
      "    return await self._call_function_tool(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<7 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/pydantic_ai/_tool_manager.py\", line 237, in _call_function_tool\n",
      "    tool_result = await self._call_tool(call, allow_partial, wrap_validation_errors)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/pydantic_ai/_tool_manager.py\", line 160, in _call_tool\n",
      "    result = await self.toolset.call_tool(name, args_dict, ctx, tool)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/pydantic_ai/toolsets/combined.py\", line 90, in call_tool\n",
      "    return await tool.source_toolset.call_tool(name, tool_args, ctx, tool.source_tool)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/pydantic_ai/toolsets/combined.py\", line 90, in call_tool\n",
      "    return await tool.source_toolset.call_tool(name, tool_args, ctx, tool.source_tool)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/pydantic_ai/toolsets/function.py\", line 350, in call_tool\n",
      "    return await tool.call_func(tool_args, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/pydantic_ai/_function_schema.py\", line 55, in call\n",
      "    return await run_in_executor(function, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/pydantic_ai/_utils.py\", line 47, in run_in_executor\n",
      "    return await run_sync(wrapped_func)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 2485, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 976, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/var/folders/km/dql4gckx6ps4lrl0mdrhnsbh0000gn/T/ipykernel_76718/2606569480.py\", line 25, in vector_search\n",
      "    query_points = qd_client.query_points(\n",
      "        collection_name=collection_name,\n",
      "    ...<2 lines>...\n",
      "        with_payload=True\n",
      "    )\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/qdrant_client/qdrant_client.py\", line 562, in query_points\n",
      "    next(\n",
      "    ~~~~^\n",
      "        iter(\n",
      "        ^^^^^\n",
      "    ...<3 lines>...\n",
      "        )\n",
      "        ^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/qdrant_client/qdrant_fastembed.py\", line 875, in _embed_models\n",
      "    yield from self._model_embedder.embed_models(\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/qdrant_client/embed/model_embedder.py\", line 71, in embed_models\n",
      "    yield from self.embed_models_batch(\n",
      "        raw_models_batch, is_query, inference_batch_size=batch_size\n",
      "    )\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/qdrant_client/embed/model_embedder.py\", line 147, in embed_models_batch\n",
      "    yield from (\n",
      "    ...<7 lines>...\n",
      "    )\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/qdrant_client/embed/model_embedder.py\", line 148, in <genexpr>\n",
      "    self._process_model(\n",
      "    ~~~~~~~~~~~~~~~~~~~^\n",
      "        raw_model,\n",
      "        ^^^^^^^^^^\n",
      "    ...<2 lines>...\n",
      "        inference_batch_size=inference_batch_size,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/qdrant_client/embed/model_embedder.py\", line 233, in _process_model\n",
      "    self._drain_accumulator(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        data, is_query=is_query, inference_batch_size=inference_batch_size\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/qdrant_client/embed/model_embedder.py\", line 315, in _drain_accumulator\n",
      "    self._embed_accumulator(is_query=is_query, inference_batch_size=inference_batch_size)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/qdrant_client/embed/model_embedder.py\", line 391, in _embed_accumulator\n",
      "    for model, data in self._batch_accumulator.items():\n",
      "                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "RuntimeError: dictionary changed size during iteration\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='vector_search' coro=<_call_tool() done, defined at /Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/pydantic_ai/_agent_graph.py:1026> exception=RuntimeError('dictionary changed size during iteration')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/pydantic_ai/_agent_graph.py\", line 1033, in _call_tool\n",
      "    tool_result = await tool_manager.handle_call(tool_call)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/pydantic_ai/_tool_manager.py\", line 112, in handle_call\n",
      "    return await self._call_function_tool(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<7 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/pydantic_ai/_tool_manager.py\", line 237, in _call_function_tool\n",
      "    tool_result = await self._call_tool(call, allow_partial, wrap_validation_errors)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/pydantic_ai/_tool_manager.py\", line 160, in _call_tool\n",
      "    result = await self.toolset.call_tool(name, args_dict, ctx, tool)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/pydantic_ai/toolsets/combined.py\", line 90, in call_tool\n",
      "    return await tool.source_toolset.call_tool(name, tool_args, ctx, tool.source_tool)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/pydantic_ai/toolsets/combined.py\", line 90, in call_tool\n",
      "    return await tool.source_toolset.call_tool(name, tool_args, ctx, tool.source_tool)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/pydantic_ai/toolsets/function.py\", line 350, in call_tool\n",
      "    return await tool.call_func(tool_args, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/pydantic_ai/_function_schema.py\", line 55, in call\n",
      "    return await run_in_executor(function, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/pydantic_ai/_utils.py\", line 47, in run_in_executor\n",
      "    return await run_sync(wrapped_func)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 2485, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 976, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/var/folders/km/dql4gckx6ps4lrl0mdrhnsbh0000gn/T/ipykernel_76718/2606569480.py\", line 25, in vector_search\n",
      "    query_points = qd_client.query_points(\n",
      "        collection_name=collection_name,\n",
      "    ...<2 lines>...\n",
      "        with_payload=True\n",
      "    )\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/qdrant_client/qdrant_client.py\", line 562, in query_points\n",
      "    next(\n",
      "    ~~~~^\n",
      "        iter(\n",
      "        ^^^^^\n",
      "    ...<3 lines>...\n",
      "        )\n",
      "        ^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/qdrant_client/qdrant_fastembed.py\", line 875, in _embed_models\n",
      "    yield from self._model_embedder.embed_models(\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/qdrant_client/embed/model_embedder.py\", line 71, in embed_models\n",
      "    yield from self.embed_models_batch(\n",
      "        raw_models_batch, is_query, inference_batch_size=batch_size\n",
      "    )\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/qdrant_client/embed/model_embedder.py\", line 147, in embed_models_batch\n",
      "    yield from (\n",
      "    ...<7 lines>...\n",
      "    )\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/qdrant_client/embed/model_embedder.py\", line 148, in <genexpr>\n",
      "    self._process_model(\n",
      "    ~~~~~~~~~~~~~~~~~~~^\n",
      "        raw_model,\n",
      "        ^^^^^^^^^^\n",
      "    ...<2 lines>...\n",
      "        inference_batch_size=inference_batch_size,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/qdrant_client/embed/model_embedder.py\", line 233, in _process_model\n",
      "    self._drain_accumulator(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        data, is_query=is_query, inference_batch_size=inference_batch_size\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/qdrant_client/embed/model_embedder.py\", line 315, in _drain_accumulator\n",
      "    self._embed_accumulator(is_query=is_query, inference_batch_size=inference_batch_size)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kasteion/repos/kasteion/ai-bootcamp-project/.venv/lib/python3.13/site-packages/qdrant_client/embed/model_embedder.py\", line 391, in _embed_accumulator\n",
      "    for model, data in self._batch_accumulator.items():\n",
      "                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "RuntimeError: dictionary changed size during iteration\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = []\n",
    "\n",
    "for i, doc in enumerate(chunks):\n",
    "    text = doc.content\n",
    "    text = text.strip()\n",
    "    vector = models.Document(text=text, model=model_name)\n",
    "\n",
    "\n",
    "    if (len(text) > 0):\n",
    "        point = models.PointStruct(id=i, vector=vector, payload={ 'title': doc.title, 'content': doc.content, 'key': doc.key })\n",
    "        points.append(point)\n",
    "\n",
    "qd_client.upsert(\n",
    "    collection_name=collection_name,\n",
    "    points=points\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fdb9b83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai.messages import FunctionToolCallEvent\n",
    "\n",
    "class NamedCallback:\n",
    "\n",
    "    def __init__(self, agent):\n",
    "        self.agent_name = agent.name\n",
    "\n",
    "    async def print_function_calls(self, ctx, event):\n",
    "        # Detect nested streams\n",
    "        if hasattr(event, \"__aiter__\"):\n",
    "            async for sub in event:\n",
    "                await self.print_function_calls(ctx, sub)\n",
    "            return\n",
    "\n",
    "        if isinstance(event, FunctionToolCallEvent):\n",
    "            tool_name = event.part.tool_name\n",
    "            args = event.part.args\n",
    "            print(f\"TOOL CALL ({self.agent_name}): {tool_name}({args})\")\n",
    "\n",
    "    async def __call__(self, ctx, event):\n",
    "        return await self.print_function_calls(ctx, event)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "033a15f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List\n",
    "\n",
    "class SearchResult(TypedDict):\n",
    "    \"\"\"Represents a single search result entry.\"\"\"\n",
    "    title: str\n",
    "    content: str\n",
    "    key: str\n",
    "\n",
    "class SearchTools:\n",
    "    def vector_search(self, query: str, num_results=15) -> List[SearchResult]:\n",
    "        \"\"\"\n",
    "        Performs a vector search looking for lyrics related with the query.\n",
    "\n",
    "        Args:\n",
    "            query (str): The search query string.\n",
    "\n",
    "        Returns:\n",
    "            List[SearchResult]: A list of search results. Each result dictionary contains:\n",
    "                - title (str): The title of the song.\n",
    "                - content (str): The content of the song that matched.\n",
    "                - key (str): The key the of the song.\n",
    "        \"\"\"\n",
    "        vector = models.Document(text=query, model=model_name)\n",
    "\n",
    "        query_points = qd_client.query_points(\n",
    "            collection_name=collection_name,\n",
    "            query=vector,\n",
    "            limit=num_results,\n",
    "            with_payload=True\n",
    "        )\n",
    "\n",
    "        results = []\n",
    "\n",
    "        for point in query_points.points:\n",
    "            results.append(point.payload)\n",
    "\n",
    "        return results\n",
    "\n",
    "    def get_full_song_by_title(self, title: str) -> SearchResult:\n",
    "        \"\"\"\n",
    "        Retrieve full song by title\n",
    "\n",
    "        Args:\n",
    "            title (str): The title of the song\n",
    "        \n",
    "        Returns:\n",
    "            SearchResult: The full song\n",
    "                - title (str): The title of the song.\n",
    "                - content (str): The content of the song.\n",
    "                - key (str): The key the of the song.\n",
    "        \"\"\"\n",
    "        sections = [chunk for chunk in chunks if chunk.title == title]\n",
    "        if len(sections) == 0:\n",
    "            return \"\"\n",
    "        \n",
    "        title = sections[0].title\n",
    "        key = sections[0].key\n",
    "        content = ' '.join([section.content for section in sections])\n",
    "        return SearchResult(title = title, content=content, key=key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3dbe239c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = SearchTools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e0765688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': '2da de Corintios 5:17', 'content': 'El que está en Cristo es nueva criatura. Las cosas viejas pasaron ya. He aquí todas son hechas nuevas, Así se inicia el primer amor. Por Cristo vivimos, en Cristo morimos, En Él redimimos el mal que hicimos. Su sangre nos limpia de todo pecado Y así el pasado queda sepultado.', 'key': 'G'}\n"
     ]
    }
   ],
   "source": [
    "# import re\n",
    "# section_content = re.sub(r\"\\[[^\\]]+\\]\", \"\", songs[1].content)\n",
    "# print(section_content)\n",
    "print(tools.get_full_song_by_title(\"2da de Corintios 5:17\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b0ae283d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'En totalidad a Ti, Rindo alma y corazón, No tengo nada más que dar Tómalo mi buen Señor Tómame en tus brazos Cristo, Toma mi vida en tus manos Y haz de mi lo que Tú quieras, Tómame aquí estoy Tómame aquí estoy'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([chunk.content for chunk in chunks if chunk.title == 'En Totalidad a Ti'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e2d926ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class Search(BaseModel):\n",
    "    \"\"\"keyword used for search and the song titles found\"\"\"\n",
    "    keyword: str = Field(..., description=\"The keyword searched\")\n",
    "    titles: List[str] = Field(..., description = \"A list of song titles from the search results\")\n",
    "\n",
    "class SearchPhase(BaseModel):\n",
    "    \"\"\"A list of the searches done by keyword and the relevant songs found\"\"\"\n",
    "    searches: List[Search] = Field(..., description=\"A list of at 5 searches done to find relevant songs\")\n",
    "\n",
    "class SongList(BaseModel):\n",
    "    \"List of recommended songs with a score\"\n",
    "    title: str = Field(..., description=\"The title of the recommended song\")\n",
    "    key: str = Field(..., description=\"Key of the recommended song\")\n",
    "\n",
    "class SongScore(BaseModel):\n",
    "    \"\"\"\"\"\"\n",
    "    title: str = Field(..., description=\"The title of the recommended song\")\n",
    "    key: str = Field(..., description=\"The key of the recommended song\")\n",
    "    score: int = Field(..., description=\"The score of the recommended song based on it's relevance\")\n",
    "\n",
    "class RepertoireEvaluation(BaseModel):\n",
    "    \"Final repertoire evaluation\"\n",
    "    songScores: List[SongScore] = Field(..., description=\"A list of 5 song titles with key and score\")\n",
    "    score: int = Field(..., description=\"Score for the complete repertoire\")\n",
    "    justification: str = Field(..., description=\"Justification of the score given to the repertoire\")\n",
    "\n",
    "class Repertoire(BaseModel):\n",
    "    \"\"\"The complete repertoir across all phases\"\"\"\n",
    "    searchPhase: List[SearchPhase] = Field(..., description=\"Search stage report\")\n",
    "    songList: List[SongList] = Field(..., description = \"A list of 4-5 recommended songs\")\n",
    "    repertoireEvaluation: RepertoireEvaluation = Field(..., description=\"Final repertoire evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ddd26fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai import Agent\n",
    "\n",
    "instructions = \"\"\"\n",
    "Eres un agente cuyo objetivo es recomendar un listado de canciones \n",
    "basadas en un tema en el que el usuario se quiera enfocar.\n",
    "\n",
    "OBJETIVO\n",
    "\n",
    "Dado el tema en que el usuario quiere enfocarse, ejecuta búsquedas \n",
    "en la base de datos con la letra de las canciones para encontra canciones\n",
    "relacionadas con el tema. Encuentra 4 o 5 canciones diferentes para usar \n",
    "como repertorio de canciones basadas en ese tema.\n",
    "\n",
    "PROCESO\n",
    "\n",
    "Fase 1 - Búsqueda inicial\n",
    "\n",
    "- Tomando el input del usuario crea 5 palabras claves diferentes relacionadas con con ese tema.\n",
    "- Utiliza `vector_search()` para buscar en la base de datos canciones relacionadas con las palabras clave.\n",
    "- No te detengas hasta hacer 5 búsquedas.\n",
    "- NO HAGAS MAS DE 7 BUSQUEDAS.\n",
    "\n",
    "Fase 2 - Generar lista\n",
    "\n",
    "Con el output de la Fase 1:\n",
    "\n",
    "- Genera una lista de 4 a 5 títulos de las canciones y su key\n",
    "\n",
    "Fase 3 - Evaluar lista\n",
    "\n",
    "Con el output de la Fase 2:\n",
    "\n",
    "- Utiliza solo las canciones de la fase 2 y obten la canción completa con `get_full_song_by_title()`\n",
    "- Evalúa cada canción y asigna un score de 0 a 100 deacuerdo a que tan acertada es con respecto al tema que el usuario quiere\n",
    "- Evalúa todo el repertorio y asigna un score de 0 a 100 deacuerdo a su relevancia y al score de las canciones.\n",
    "- Escribe una justificación de score del repertorio\n",
    "- EN ESTA FASE NO TIENES PERMITIDO volver a ejecutar `vector_search()`\n",
    "\"\"\"\n",
    "\n",
    "agent_tools = [tools.vector_search, tools.get_full_song_by_title]\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"recomendations\",\n",
    "    instructions=instructions,\n",
    "    tools=agent_tools,\n",
    "    model='gpt-4o-mini',\n",
    "    output_type=Repertoire\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b3020d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOOL CALL (recomendations): vector_search({\"query\": \"fe en medio de las pruebas\"})\n",
      "TOOL CALL (recomendations): vector_search({\"query\": \"esperanza en tiempos difíciles\"})\n",
      "TOOL CALL (recomendations): vector_search({\"query\": \"fortaleza en momentos difíciles\"})\n",
      "TOOL CALL (recomendations): vector_search({\"query\": \"superar adversidades\"})\n",
      "TOOL CALL (recomendations): vector_search({\"query\": \"confianza en Dios ante las dificultades\"})\n",
      "TOOL CALL (recomendations): get_full_song_by_title({\"title\": \"Creo en Ti\"})\n",
      "TOOL CALL (recomendations): get_full_song_by_title({\"title\": \"Al Rey de reyes - A Ti sea la gloria\"})\n",
      "TOOL CALL (recomendations): get_full_song_by_title({\"title\": \"Santo\"})\n",
      "TOOL CALL (recomendations): get_full_song_by_title({\"title\": \"Dios de lo Imposible\"})\n",
      "TOOL CALL (recomendations): get_full_song_by_title({\"title\": \"Gloria a ti, Jes\\u0015\"})\n",
      "TOOL CALL (recomendations): get_full_song_by_title({\"title\": \"10000 Razones\"})\n",
      "TOOL CALL (recomendations): get_full_song_by_title({\"title\": \"En Jesucristo fuente de paz\"})\n",
      "TOOL CALL (recomendations): get_full_song_by_title({\"title\": \"Cuando estemos en gloria\"})\n",
      "TOOL CALL (recomendations): get_full_song_by_title({\"title\": \"Desde ahora, voy a alabar\"})\n",
      "TOOL CALL (recomendations): get_full_song_by_title({\"title\": \"Eres mi amigo fiel\"})\n",
      "TOOL CALL (recomendations): get_full_song_by_title({\"title\": \"Cuando estemos en gloria\"})\n",
      "TOOL CALL (recomendations): get_full_song_by_title({\"title\": \"Desde ahora, voy a alabar\"})\n",
      "TOOL CALL (recomendations): get_full_song_by_title({\"title\": \"Me viniste a rescatar\"})\n",
      "TOOL CALL (recomendations): get_full_song_by_title({\"title\": \"Eres mi amigo fiel\"})\n",
      "TOOL CALL (recomendations): get_full_song_by_title({\"title\": \"Al que nos Amo\"})\n",
      "TOOL CALL (recomendations): get_full_song_by_title({\"title\": \"Al que nos Amo\"})\n",
      "TOOL CALL (recomendations): get_full_song_by_title({\"title\": \"Me viniste a rescatar\"})\n",
      "TOOL CALL (recomendations): get_full_song_by_title({\"title\": \"Cuando estemos en gloria\"})\n",
      "TOOL CALL (recomendations): get_full_song_by_title({\"title\": \"Desde ahora, voy a alabar\"})\n",
      "TOOL CALL (recomendations): get_full_song_by_title({\"title\": \"10000 Razones\"})\n",
      "TOOL CALL (recomendations): get_full_song_by_title({\"title\": \"En Jesucristo fuente de paz\"})\n"
     ]
    }
   ],
   "source": [
    "results = await agent.run(\n",
    "    user_prompt='Quiero un set de canciones enfocadas en la fe en medio de las pruebas',\n",
    "    event_stream_handler=NamedCallback(agent)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "36ec7185",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = results.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f4cca6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Phase: \n",
      " keyword: perdón\n",
      "    - Cristo yo te amo\n",
      "    - Reina Dios\n",
      "    - Gracias Cristo\n",
      "    - Santo\n",
      "    - El Amor de Dios es maravilloso\n",
      " keyword: restauración espiritual\n",
      "    - Reina Dios\n",
      "    - Cristo yo te amo\n",
      "    - Gracias Cristo\n",
      "    - Santo\n",
      "    - El Amor de Dios es maravilloso\n",
      " keyword: redención\n",
      "    - Cristo yo te amo\n",
      "    - Aquel que nos amó\n",
      "    - Santo, santo, grande eterno Dios\n",
      "    - En Ti\n",
      "    - Gracias Cristo\n",
      " keyword: sanación\n",
      "    - Cristo yo te amo\n",
      "    - El Amor de Dios es maravilloso\n",
      "    - Dios Poderoso\n",
      "    - Cuán Grande es Dios\n",
      "    - Gracias Cristo\n",
      " keyword: reconciliación\n",
      "    - Santo\n",
      "    - Cordero\n",
      "    - Cantad alegres al Señor\n",
      "    - 10000 Razones\n",
      "    - En Jesucristo fuente de paz\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Search Phase: \")\n",
    "for phase in output.searchPhase:\n",
    "    for search in phase.searches:\n",
    "        print(\" keyword:\", search.keyword)\n",
    "        for title in search.titles:\n",
    "            print(\"    -\", title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "14d2c135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listado:\n",
      "  - Cristo yo te amo G\n",
      "  - Reina Dios A\n",
      "  - Gracias Cristo A\n",
      "  - Santo D\n",
      "  - Aquel que nos amó G\n"
     ]
    }
   ],
   "source": [
    "print(\"Listado:\")\n",
    "for song in output.songList:\n",
    "    print(\"  -\", song.title, song.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a66bf7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Te recomiendo tocar las siguientes canciones:\n",
      "  - 'Creo en Ti' en clave de A con una relevancia del: 90%\n",
      "  - 'Al Rey de reyes - A Ti sea la gloria' en clave de A con una relevancia del: 85%\n",
      "  - 'Santo' en clave de D con una relevancia del: 80%\n",
      "  - 'Dios de lo Imposible' en clave de C con una relevancia del: 90%\n",
      "  - '10000 Razones' en clave de C con una relevancia del: 95%\n",
      "\n",
      "Luego de la evaluación este repertorio tiene una relvancia del 88%\n",
      "\n",
      "Justificación:\n",
      "Este repertorio refleja muy bien el tema de la fe en medio de las pruebas. Las canciones seleccionadas hablan de confianza, adoración y esperanza divina, elementos esenciales para enfrentar tiempos difíciles. Las canciones puntuadas más alto abordan directamente el fortalecimiento de la fe y la alabanza a Dios en momentos de dificultad.\n"
     ]
    }
   ],
   "source": [
    "print(\"Te recomiendo tocar las siguientes canciones:\")\n",
    "evaluation = output.repertoireEvaluation\n",
    "for song in evaluation.songScores:\n",
    "    print(f\"  - '{song.title}' en clave de {song.key} con una relevancia del: {song.score}%\")\n",
    "\n",
    "print()\n",
    "print(f\"Luego de la evaluación este repertorio tiene una relvancia del {evaluation.score}%\")\n",
    "\n",
    "print()\n",
    "print(\"Justificación:\")\n",
    "print(evaluation.justification)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-bootcamp-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
